import json
import uuid
from typing import TypedDict, Annotated, Sequence, List, Coroutine, Any, Optional
from datetime import datetime
import pytz

import psycopg
from langchain_core.messages import (
    BaseMessage,
    HumanMessage,
    AIMessage,
    AIMessageChunk,
    ToolMessage,
)
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableConfig
from langchain_deepseek import ChatDeepSeek
import os

from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.graph.state import CompiledStateGraph
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.graph import add_messages, StateGraph, START
from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver
from langgraph.typing import StateT

from config import config as app_config

from llm.llm_chat_with_tools.tools.calculate_tools import calculate_tools, advanced_math
from llm.llm_chat_with_tools.tools.search_tools import (
    search_tool,
    web_crawler,
)
from llm.llm_chat_with_tools.tools.result_processor import (
    result_processor,
    ProcessingMode,
)


# é…ç½®éªŒè¯
app_config.validate()


class ChatState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]


def get_current_time_prompt() -> str:
    """è·å–åŒ…å«å½“å‰æ—¶é—´ä¿¡æ¯çš„ç³»ç»Ÿæç¤ºè¯"""
    # è·å–ä¸­å›½æ—¶é—´ï¼ˆä¸œå…«åŒºï¼‰
    china_tz = pytz.timezone("Asia/Shanghai")
    current_time = datetime.now(china_tz)

    # æ ¼å¼åŒ–æ—¶é—´ä¿¡æ¯
    time_str = current_time.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
    weekday_map = {
        0: "æ˜ŸæœŸä¸€",
        1: "æ˜ŸæœŸäºŒ",
        2: "æ˜ŸæœŸä¸‰",
        3: "æ˜ŸæœŸå››",
        4: "æ˜ŸæœŸäº”",
        5: "æ˜ŸæœŸå…­",
        6: "æ˜ŸæœŸæ—¥",
    }
    weekday = weekday_map[current_time.weekday()]

    return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIæ™ºèƒ½åŠ©æ‰‹ï¼Œæ‹¥æœ‰å¤šç§å·¥å…·èƒ½åŠ›ï¼Œè‡´åŠ›äºä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€åŠæ—¶ã€æœ‰ç”¨çš„ä¿¡æ¯å’Œè§£å†³æ–¹æ¡ˆã€‚

â° **å½“å‰æ—¶é—´**: {time_str} ({weekday}) - ä¸­å›½æ ‡å‡†æ—¶é—´ (GMT+8)

æ ¸å¿ƒèƒ½åŠ›ä¸å·¥å…·ï¼š
ğŸ” æ™ºèƒ½æœç´¢ï¼šå®æ—¶è·å–æœ€æ–°ç½‘ç»œä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–°é—»ã€èµ„è®¯ã€æŠ€æœ¯æ–‡æ¡£ç­‰
ğŸŒ ç½‘é¡µçˆ¬å–ï¼šæ·±åº¦è§£æç½‘é¡µå†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯å’Œè¯¦ç»†æ•°æ®  
ğŸ§® æ•°å­¦è®¡ç®—ï¼šå¤„ç†å„ç§æ•°å­¦è¿ç®—ã€ç»Ÿè®¡åˆ†æå’Œè®¡ç®—é—®é¢˜
ğŸ“Š æ•°æ®æŸ¥è¯¢ï¼šæŸ¥è¯¢æ•°æ®åº“ä¿¡æ¯ï¼Œå¦‚å­¦ç”Ÿæˆç»©ç»Ÿè®¡ç­‰

å·¥ä½œåŸåˆ™ï¼š
1. ä¿¡æ¯å‡†ç¡®æ€§ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢å·¥å…·è·å–æœ€æ–°ã€çœŸå®çš„æ•°æ®ï¼Œé¿å…è¿‡æ—¶ä¿¡æ¯
2. æ¥æºæ ‡æ³¨ï¼šæ˜ç¡®æ ‡å‡ºä¿¡æ¯æ¥æºï¼Œæä¾›å¯éªŒè¯çš„å‚è€ƒé“¾æ¥
3. æ·±åº¦åˆ†æï¼šæœç´¢åæ ¹æ®éœ€è¦ä½¿ç”¨ç½‘é¡µçˆ¬å–å·¥å…·è·å–è¯¦ç»†å†…å®¹
4. ç»“æ„åŒ–å›ç­”ï¼šä»¥æ¸…æ™°ã€æœ‰æ¡ç†çš„æ–¹å¼ç»„ç»‡å’Œå‘ˆç°ä¿¡æ¯
5. ä¸»åŠ¨æ€è€ƒï¼šç†è§£ç”¨æˆ·çœŸå®æ„å›¾ï¼Œæä¾›è¶…å‡ºé¢„æœŸçš„æœ‰ä»·å€¼å»ºè®®
6. æ—¶é—´æ„ŸçŸ¥ï¼šå……åˆ†åˆ©ç”¨å½“å‰æ—¶é—´ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·æä¾›æ—¶æ•ˆæ€§å‡†ç¡®çš„å›ç­”

å“åº”ç­–ç•¥ï¼š
- å¯¹äºæ—¶æ•ˆæ€§å¼ºçš„é—®é¢˜ï¼ˆå¤©æ°”ã€æ–°é—»ã€è‚¡ä»·ç­‰ï¼‰ï¼Œå¿…é¡»ä½¿ç”¨æœç´¢å·¥å…·
- å¯¹äºéœ€è¦è¯¦ç»†ä¿¡æ¯çš„æŸ¥è¯¢ï¼Œå…ˆæœç´¢æ¦‚å†µï¼Œå†çˆ¬å–å…·ä½“å†…å®¹
- å¯¹äºè®¡ç®—ç±»é—®é¢˜ï¼Œä½¿ç”¨è®¡ç®—å·¥å…·ç¡®ä¿å‡†ç¡®æ€§
- å¯¹äºæ•°æ®æŸ¥è¯¢éœ€æ±‚ï¼Œä½¿ç”¨ç›¸åº”çš„æŸ¥è¯¢å·¥å…·
- å¯¹äºæ—¶é—´ç›¸å…³çš„æŸ¥è¯¢ï¼Œå‚è€ƒå½“å‰æ—¶é—´æä¾›å‡†ç¡®ä¿¡æ¯
- å§‹ç»ˆä»¥ç”¨æˆ·éœ€æ±‚ä¸ºå¯¼å‘ï¼Œçµæ´»è¿ç”¨å„ç§å·¥å…·ç»„åˆ

è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜çš„æ€§è´¨ï¼Œæ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ç»„åˆæ¥æä¾›æœ€ä½³è§£å†³æ–¹æ¡ˆã€‚"""


client = MultiServerMCPClient(
    {
        "Student_Grade_System": {
            "url": app_config.mcp_server_url,
            "transport": "streamable_http",
        }
    }
)

mcp_tools = []


async def get_tools():
    global mcp_tools
    mcp_tools = await client.get_tools()


class ChatBot:
    def __init__(
        self,
        model: str = "Qwen/Qwen2.5-7B-Instruct",
        enable_result_processing: bool = True,
    ):
        """
        ChatBotåˆå§‹åŒ–
        :param model: æ¨¡å‹åç§°
        :param enable_result_processing: æ˜¯å¦å¯ç”¨ç»“æœå¤„ç†
        """
        self.llm = ChatDeepSeek(
            model=model,
            verbose=False,
            temperature=0.6,
            # extra_body={"thinking_budget": 1024},
        )
        self.tools = [
            search_tool,
            calculate_tools,
            advanced_math,
            web_crawler,
        ]
        self.llm_with_tools = None
        self.tool_node = None
        self.enable_result_processing = enable_result_processing
        self.result_processor = result_processor

        # åˆå§‹åŒ–æ—¶ä¸åˆ›å»ºpromptï¼Œåœ¨chatbotæ–¹æ³•ä¸­åŠ¨æ€ç”Ÿæˆ

        self.chain = None

        # ç±»å‹æ³¨è§£ï¼šæ˜ç¡®graphçš„ç±»å‹ï¼Œå¸®åŠ©IDEæä¾›ä»£ç è¡¥å…¨
        # åˆå§‹åŒ–æ—¶ä¸ºNoneï¼Œè°ƒç”¨initialize()åä¼šè¢«æ­£ç¡®åˆå§‹åŒ–
        self.memory: Optional[AsyncPostgresSaver] = None
        self.graph: Optional[CompiledStateGraph[ChatState]] = None

    async def initialize(self):
        conn = await psycopg.AsyncConnection.connect(
            app_config.database_url,
            autocommit=True,
        )
        self.memory = AsyncPostgresSaver(conn)

        await self.memory.setup()
        if not self.llm_with_tools:
            await get_tools()
            self.tools.extend(mcp_tools)
            print(self.tools)
            self.llm_with_tools = self.llm.bind_tools(tools=self.tools)
            self.tool_node = ToolNode(tools=self.tools)
        self.graph = await self.create_graph()

    async def chatbot(self, state: ChatState):
        """
        chatbotèŠ‚ç‚¹
        :param state: langgraphçŠ¶æ€
        :return: æ–°langgraphçŠ¶æ€ï¼ŒåŒ…å«llm_out
        """
        messages = state["messages"]
        print(f"messages: {messages}")
        print("chatbot")

        # åŠ¨æ€åˆ›å»ºåŒ…å«å½“å‰æ—¶é—´çš„prompt
        current_prompt = ChatPromptTemplate.from_messages(
            [("system", get_current_time_prompt()), ("placeholder", "{messages}")]
        )

        # åˆ›å»ºåŒ…å«å½“å‰æ—¶é—´ä¿¡æ¯çš„chain
        chain = current_prompt | self.llm_with_tools

        response = await chain.ainvoke({"messages": messages})
        return {"messages": response}

    async def process_tool_results(self, state: ChatState):
        """
        å¤„ç†å·¥å…·æ‰§è¡Œç»“æœçš„èŠ‚ç‚¹
        """
        messages = state["messages"]
        processed_messages = []

        length = len(messages)
        for i in range(length - 1, -1, -1):
            message = messages[i]
            if isinstance(message, HumanMessage):
                break
            if isinstance(message, ToolMessage) and self.enable_result_processing:
                # è·å–å·¥å…·åç§°
                tool_name = getattr(message, "name", "unknown_tool")
                original_content = message.content

                try:
                    # å¦‚æœæ˜¯MCPå·¥å…·ç»“æœï¼Œè¿›è¡Œå¤„ç†
                    if any(
                        tool_name.startswith(prefix)
                        for prefix in ["get_", "query_", "fetch_"]
                    ):
                        processed_content = await self.result_processor.process_result(
                            tool_name=tool_name,
                            result=original_content,
                            mode=ProcessingMode.FORMATTED,
                        )
                        message.content = processed_content
                except Exception as e:
                    print(f"å¤„ç†å·¥å…·ç»“æœæ—¶å‡ºé”™: {e}")
                    # ä¿æŒåŸå§‹å†…å®¹

            processed_messages.append(message)

        return {"messages": processed_messages}

    async def create_graph(self):
        if self.memory is None:
            raise ValueError("Memory not initialized. Call initialize() first.")

        graph_builder = StateGraph(ChatState)
        graph_builder.add_node("chatbot", self.chatbot, metadata={"name": "chatbot"})
        graph_builder.add_node("tools", self.tool_node, metadata={"name": "search"})

        if self.enable_result_processing:
            graph_builder.add_node(
                "process_results",
                self.process_tool_results,
                metadata={"name": "process_results"},
            )

        graph_builder.add_edge(START, "chatbot")
        graph_builder.add_conditional_edges("chatbot", tools_condition)

        if self.enable_result_processing:
            graph_builder.add_edge("tools", "process_results")
            graph_builder.add_edge("process_results", "chatbot")
        else:
            graph_builder.add_edge("tools", "chatbot")

        return graph_builder.compile(checkpointer=self.memory)

    async def generate(
        self, query: str, thread_id: str, summary_with_llm: bool = False
    ):
        """
        å¯¹è¯å†…å®¹ç”Ÿæˆ
        :param query: é—®é¢˜å†…å®¹
        :param thread_id: çº¿ç¨‹id
        :param summary_with_llm: æ˜¯å¦å¯ç”¨LLMæ™ºèƒ½æ€»ç»“åŠŸèƒ½
        :return: streamè¿”å›llmå†…å®¹
        """
        if self.graph is None:
            await self.initialize()

        # ç±»å‹æ–­è¨€ï¼šå‘Šè¯‰IDEæ­¤æ—¶graphä¸ä¸ºNoneï¼Œæä¾›å®Œæ•´çš„ä»£ç è¡¥å…¨
        assert self.graph is not None, "Graph should be initialized"

        config: RunnableConfig = RunnableConfig(
            configurable={"thread_id": thread_id, "summary_with_llm": summary_with_llm}
        )
        full_messages = ""

        print("Start Chat:")
        async for chunk in self.graph.astream(
            {"messages": HumanMessage(content=query)},
            config=config,
            stream_mode="messages",
        ):
            # print(chunk)
            event = chunk[0]
            config = chunk[1]
            if isinstance(event, AIMessageChunk):
                if config.get("name") and (
                    config["name"] == "search" or config["name"] == "process_results"
                ):
                    continue
                full_messages += event.content
                print(event.content, end="")
            yield f"data: {json.dumps(dict(chunk[0]), ensure_ascii=False)}\n\n"
        # print(f"\nfull_messages:\n {full_messages}")
        yield "data: [DONE]\n"

    async def named_chat(self, thread_id: str) -> str:
        """
        æ ¹æ®å¯¹è¯å†…å®¹ç»™å¯¹è¯å‘½åï¼Œç”Ÿæˆç®€æ´æœ‰æ„ä¹‰çš„å¯¹è¯æ ‡é¢˜
        :param thread_id: çº¿ç¨‹ID
        :return: å¯¹è¯æ ‡é¢˜ï¼Œå¦‚æœå¤±è´¥è¿”å›é»˜è®¤æ ‡é¢˜
        """
        if self.graph is None:
            await self.initialize()

        assert self.graph is not None, "Graph should be initialized"

        config: RunnableConfig = RunnableConfig(configurable={"thread_id": thread_id})
        try:
            # è·å–å¯¹è¯å†å²
            state = await self.graph.aget_state(config)
            if not (state and state.values and "messages" in state.values):
                return "æ–°å¯¹è¯"

            messages: List[BaseMessage] = state.values["messages"]
            if not messages:
                return "æ–°å¯¹è¯"

            # æå–å¯¹è¯å†…å®¹ç”¨äºç”Ÿæˆæ ‡é¢˜
            conversation_content = self._extract_conversation_for_naming(messages)
            if not conversation_content.strip():
                return "æ–°å¯¹è¯"

            # åˆ›å»ºä¸“é—¨çš„å‘½åæç¤ºè¯
            naming_prompt = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¯¹è¯æ ‡é¢˜ç”ŸæˆåŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´ã€å‡†ç¡®ã€æœ‰æ„ä¹‰çš„å¯¹è¯æ ‡é¢˜ã€‚

è¦æ±‚ï¼š
1. æ ‡é¢˜é•¿åº¦æ§åˆ¶åœ¨8-15ä¸ªå­—ç¬¦
2. å‡†ç¡®æ¦‚æ‹¬å¯¹è¯çš„ä¸»è¦è¯é¢˜æˆ–å†…å®¹
3. ä½¿ç”¨ç®€æ´æ˜äº†çš„ä¸­æ–‡è¡¨è¾¾
4. é¿å…ä½¿ç”¨"å…³äº"ã€"è®¨è®º"ç­‰å†—ä½™è¯æ±‡
5. çªå‡ºå¯¹è¯çš„æ ¸å¿ƒä¸»é¢˜æˆ–å…³é”®è¯
6. å¦‚æœæ˜¯æŠ€æœ¯é—®é¢˜ï¼Œå¯ä»¥åŒ…å«æŠ€æœ¯å…³é”®è¯
7. å¦‚æœæ˜¯æ—¥å¸¸å¯¹è¯ï¼Œçªå‡ºä¸»è¦è¯é¢˜

ç¤ºä¾‹ï¼š
- å¯¹è¯æ¶‰åŠPythonç¼–ç¨‹ â†’ "Pythonç¼–ç¨‹é—®é¢˜"
- è®¨è®ºæœºå™¨å­¦ä¹ ç®—æ³• â†’ "æœºå™¨å­¦ä¹ ç®—æ³•"
- è¯¢é—®å¤©æ°”æƒ…å†µ â†’ "å¤©æ°”æŸ¥è¯¢"
- æ•°å­¦è®¡ç®—é—®é¢˜ â†’ "æ•°å­¦è®¡ç®—"
- å·¥ä½œè§„åˆ’è®¨è®º â†’ "å·¥ä½œè§„åˆ’"

è¯·ç›´æ¥è¾“å‡ºæ ‡é¢˜ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–é¢å¤–æ–‡å­—ã€‚""",
                    ),
                    ("human", "è¯·ä¸ºä»¥ä¸‹å¯¹è¯ç”Ÿæˆæ ‡é¢˜ï¼š\n\n{conversation}"),
                ]
            )

            # åˆ›å»ºå‘½åé“¾
            naming_chain = naming_prompt | self.llm

            # ç”Ÿæˆæ ‡é¢˜
            response = await naming_chain.ainvoke(
                {"conversation": conversation_content}
            )

            # æå–å¹¶æ¸…ç†æ ‡é¢˜
            title = self._clean_generated_title(
                response.content if hasattr(response, "content") else str(response)
            )

            print(f"ä¸ºå¯¹è¯ {thread_id} ç”Ÿæˆæ ‡é¢˜: {title}")
            return title

        except Exception as e:
            print(f"Error generating chat name: {e}")
            return "æ–°å¯¹è¯"

    def _extract_conversation_for_naming(self, messages: List[BaseMessage]) -> str:
        """
        ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–ç”¨äºå‘½åçš„å…³é”®å¯¹è¯å†…å®¹
        :param messages: æ¶ˆæ¯åˆ—è¡¨
        :return: æå–çš„å¯¹è¯å†…å®¹
        """
        conversation_parts = []
        human_messages = []
        ai_messages = []

        # æå–å‰å‡ è½®å¯¹è¯ï¼Œé‡ç‚¹å…³æ³¨ç”¨æˆ·é—®é¢˜å’ŒAIå›ç­”
        for message in messages:
            if isinstance(message, HumanMessage):
                human_messages.append(message.content)
            elif isinstance(message, AIMessage):
                ai_messages.append(message.content)

        # ä¼˜å…ˆä½¿ç”¨å‰3ä¸ªç”¨æˆ·æ¶ˆæ¯ï¼Œè¿™é€šå¸¸èƒ½åæ˜ å¯¹è¯ä¸»é¢˜
        for i, human_msg in enumerate(human_messages[:3]):
            conversation_parts.append(f"ç”¨æˆ·: {human_msg}")
            # å¦‚æœæœ‰å¯¹åº”çš„AIå›ç­”ï¼Œä¹ŸåŒ…å«ï¼ˆä½†é™åˆ¶é•¿åº¦ï¼‰
            if i < len(ai_messages):
                ai_response = ai_messages[i][:200]  # é™åˆ¶AIå›ç­”é•¿åº¦
                conversation_parts.append(f"åŠ©æ‰‹: {ai_response}")

        # ç»„åˆå¯¹è¯å†…å®¹ï¼Œæ§åˆ¶æ€»é•¿åº¦
        conversation_text = "\n".join(conversation_parts)

        # é™åˆ¶æ€»é•¿åº¦ï¼Œé¿å…tokenè¿‡å¤š
        if len(conversation_text) > 1000:
            conversation_text = conversation_text[:1000] + "..."

        return conversation_text

    def _clean_generated_title(self, raw_title: str) -> str:
        """
        æ¸…ç†å’Œä¼˜åŒ–ç”Ÿæˆçš„æ ‡é¢˜
        :param raw_title: åŸå§‹ç”Ÿæˆçš„æ ‡é¢˜
        :return: æ¸…ç†åçš„æ ‡é¢˜
        """
        if not raw_title:
            return "æ–°å¯¹è¯"

        # ç§»é™¤å¯èƒ½çš„å¼•å·ã€æ¢è¡Œç¬¦ç­‰
        title = raw_title.strip().strip('"\'""' "").strip()

        # ç§»é™¤å¯èƒ½çš„å‰ç¼€
        prefixes_to_remove = [
            "æ ‡é¢˜ï¼š",
            "æ ‡é¢˜:",
            "å¯¹è¯æ ‡é¢˜ï¼š",
            "å¯¹è¯æ ‡é¢˜:",
            "é¢˜ç›®ï¼š",
            "é¢˜ç›®:",
        ]
        for prefix in prefixes_to_remove:
            if title.startswith(prefix):
                title = title[len(prefix) :].strip()

        # é•¿åº¦æ§åˆ¶
        if len(title) > 20:
            title = title[:17] + "..."
        elif len(title) < 2:
            title = "æ–°å¯¹è¯"

        # å¦‚æœæ ‡é¢˜ä¸ºç©ºæˆ–åªåŒ…å«æ ‡ç‚¹ç¬¦å·ï¼Œè¿”å›é»˜è®¤å€¼
        if not title or title.isspace() or all(c in "ã€‚ï¼Œã€ï¼›ï¼šï¼ï¼Ÿ" for c in title):
            return "æ–°å¯¹è¯"

        return title

    async def get_history(self, thread_id: str) -> List[BaseMessage]:
        """
        è·å–å†å²è®°å½•
        :param thread_id: å¯¹è¯çº¿ç¨‹ID
        :return: å†å²è®°å½•
        """
        if self.graph is None:
            await self.initialize()

        assert self.graph is not None, "Graph should be initialized"

        config: RunnableConfig = RunnableConfig(configurable={"thread_id": thread_id})
        try:
            state = await self.graph.aget_state(config)
            if state and state.values and "messages" in state.values:
                return state.values["messages"]
            return []
        except Exception as e:
            print(f"Error getting history: {str(e)}")
            return []

    async def delete_history(self, thread_id: str) -> bool:
        """
        åˆ é™¤å†å²è®°å½•
        :param thread_id: çº¿ç¨‹ID
        :return: åˆ é™¤çŠ¶æ€
        """
        if self.graph is None:
            await self.initialize()

        assert self.memory is not None, "Memory should be initialized"

        try:
            await self.memory.adelete_thread(thread_id)
            return True
        except Exception as e:
            print(f"Error deleting history: {str(e)}")
            return False

    async def delete_history_batch(self, thread_ids: List[str]) -> bool:
        """
        æ‰¹é‡åˆ é™¤å¤šä¸ªå¯¹è¯å†å²è®°å½•
        :param thread_ids: çº¿ç¨‹IDåˆ—è¡¨
        :return: bool åˆ é™¤çŠ¶æ€
        """
        if not thread_ids:
            return False

        if self.graph is None:
            await self.initialize()

        assert self.memory is not None, "Memory should be initialized"

        success_count = 0
        for thread_id in thread_ids:
            try:
                await self.memory.adelete_thread(thread_id)
                success_count += 1
                print(f"Successfully deleted thread: {thread_id}")
            except Exception as e:
                print(f"Error deleting thread {thread_id}: {str(e)}")

        # å¦‚æœè‡³å°‘æœ‰ä¸€ä¸ªåˆ é™¤æˆåŠŸï¼Œè¿”å›True
        return success_count > 0

    async def edit_message(
        self, thread_id: str, message_idx: int, new_content: str
    ) -> bool:
        """
        ç¼–è¾‘æ¶ˆæ¯
        :param thread_id: çº¿ç¨‹ID
        :param message_idx: æ¶ˆæ¯ä½ç½®
        :param new_content: æ–°å†…å®¹
        :return: bool ç¼–è¾‘çŠ¶æ€
        """
        if self.graph is None:
            await self.initialize()

        assert self.graph is not None, "Graph should be initialized"
        assert self.memory is not None, "Memory should be initialized"

        config = RunnableConfig(configurable={"thread_id": thread_id})
        try:
            state = await self.graph.aget_state(config)
            messages = state.values.get("messages", [])
            if 0 <= message_idx < len(messages):
                if isinstance(messages[message_idx], HumanMessage):
                    messages[message_idx] = HumanMessage(content=new_content)
                elif isinstance(messages[message_idx], AIMessage):
                    messages[message_idx] = AIMessage(content=new_content)
                else:
                    raise "Unsupported message type"
                await self.memory.adelete_thread(thread_id)
                await self.graph.aupdate_state(config, {"messages": messages})
                return True
            else:
                raise f"Message index {message_idx} out of range"
        except Exception as e:
            print(f"Error on edit message: {str(e)}")
            return False

    async def edit_message_with_id(
        self, thread_id: str, message_id: str, new_content: str
    ) -> bool:
        """
        æ ¹æ®æ¶ˆæ¯IDä¿®æ”¹æ¶ˆæ¯å†…å®¹
        :param thread_id: çº¿ç¨‹ID
        :param message_id: æ¶ˆæ¯ID
        :param new_content: æ–°æ¶ˆæ¯å†…å®¹
        :return: ä¿®æ”¹çŠ¶æ€
        """
        if self.graph is None:
            await self.initialize()

        assert self.graph is not None, "Graph should be initialized"
        assert self.memory is not None, "Memory should be initialized"

        config = RunnableConfig(configurable={"thread_id": thread_id})
        try:
            state = await self.graph.aget_state(config)
            messages = state.values.get("messages", [])
            idx = -1
            for i, message in enumerate(messages):
                if message.id == message_id:
                    idx = i
                    break
            if idx != -1:
                if isinstance(messages[idx], AIMessage):
                    messages[idx] = AIMessage(new_content)
                elif isinstance(messages[idx], HumanMessage):
                    messages[idx] = HumanMessage(new_content)
                else:
                    raise "Unsupported message type"

                await self.memory.adelete_thread(thread_id)
                await self.graph.aupdate_state(config, {"messages": messages})
                return True
            else:
                raise f"Unable to find messages index {message_id}"
        except Exception as e:
            print(f"Error on edit message with id: {str(e)}")
            return False

    async def delete_message(self, thread_id: str, message_idx: int) -> bool:
        """
        åˆ é™¤æŒ‡å®šæ¶ˆæ¯
        :param thread_id: çº¿ç¨‹ID
        :param message_idx: æ¶ˆæ¯ä½ç½®
        :return: åˆ é™¤çŠ¶æ€
        """
        if self.graph is None:
            await self.initialize()

        assert self.graph is not None, "Graph should be initialized"
        assert self.memory is not None, "Memory should be initialized"

        config = RunnableConfig(configurable={"thread_id": thread_id})
        try:
            state = await self.graph.aget_state(config)
            messages = state.values.get("messages", [])
            if 0 <= message_idx < len(messages):
                messages.pop(message_idx)
                await self.memory.adelete_thread(thread_id)
                await self.graph.aupdate_state(config, {"messages": messages})
                return True
            else:
                raise f"Message index out of range"
        except Exception as e:
            print(f"Error on delete message: {str(e)}")
            return False

    async def delete_message_with_id(self, thread_id: str, message_id: str) -> bool:
        """
        æ ¹æ®æ¶ˆæ¯IDåˆ é™¤æ¶ˆæ¯
        :param thread_id: çº¿ç¨‹ID
        :param message_id: æ¶ˆæ¯ID
        :return: åˆ é™¤çŠ¶æ€
        """
        if self.graph is None:
            await self.initialize()

        assert self.graph is not None, "Graph should be initialized"
        assert self.memory is not None, "Memory should be initialized"

        config = RunnableConfig(configurable={"thread_id": thread_id})
        try:
            state = await self.graph.aget_state(config)
            messages = state.values.get("messages", [])
            idx = -1
            for i, message in enumerate(messages):
                if message.id == message_id:
                    idx = i
                    break
            if idx != -1:
                messages.pop(idx)
            else:
                raise f"Message index {message_id} out of range"
            await self.memory.adelete_thread(thread_id)
            await self.graph.aupdate_state(config, {"messages": messages})
            return True
        except Exception as e:
            print(f"Error on delete message with id: {str(e)}")
            return False

    async def delete_messages_after_with_id(
        self, thread_id: str, message_id: str
    ) -> bool:
        """
        åˆ é™¤æŒ‡å®šæ¶ˆæ¯åé¢çš„æ‰€æœ‰æ¶ˆæ¯ï¼ŒåŒ…æ‹¬è¯¥æ¶ˆæ¯
        :param thread_id: çº¿ç¨‹ID
        :param message_id: æ¶ˆæ¯ID
        :return: åˆ é™¤æƒ…å†µ
        """
        if self.graph is None:
            await self.initialize()

        assert self.graph is not None, "Graph should be initialized"
        assert self.memory is not None, "Memory should be initialized"

        config = RunnableConfig(configurable={"thread_id": thread_id})
        try:
            state = await self.graph.aget_state(config)
            messages = state.values.get("messages", [])
            idx = -1
            for i, message in enumerate(messages):
                if message.id == message_id:
                    idx = i
                    break
            if idx != -1:
                if not (
                    isinstance(messages[idx], AIMessage)
                    or isinstance(messages[idx], HumanMessage)
                ):
                    raise "Unsupported message type"
                messages = messages[:idx]
                await self.memory.adelete_thread(thread_id)
                await self.graph.aupdate_state(config, {"messages": messages})
                return True
            else:
                raise f"Message index {message_id} out of range"
        except Exception as e:
            print(f"Error on delete message with id: {str(e)}")
            return False

    async def get_message_by_id(self, thread_id: str, message_id: str) -> BaseMessage:
        """
        æ ¹æ®æ¶ˆæ¯IDè·å–æŒ‡å®šæ¶ˆæ¯
        :param thread_id: çº¿ç¨‹ID
        :param message_id: æ¶ˆæ¯ID
        :return: æ¶ˆæ¯å¯¹è±¡ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›None
        """
        if self.graph is None:
            await self.initialize()

        assert self.graph is not None, "Graph should be initialized"

        config = RunnableConfig(configurable={"thread_id": thread_id})
        try:
            state = await self.graph.aget_state(config)
            messages = state.values.get("messages", [])
            for message in messages:
                if message.id == message_id:
                    return message
            return None
        except Exception as e:
            print(f"Error getting message by id: {str(e)}")
            return None

    async def generate_test(self, query: str):
        """
        æµ‹è¯•æ–¹æ³•ï¼ˆæµ‹è¯•ç”¨ï¼‰
        :param query: é—®é¢˜
        :return: None
        """
        if self.graph is None:
            await self.initialize()

        assert self.graph is not None, "Graph should be initialized"

        config: RunnableConfig = RunnableConfig(configurable={"thread_id": "1"})
        full_messages = ""

        print("Start Chat: ")
        async for chunk in self.graph.astream(
            {"messages": HumanMessage(content=query)},
            config=config,
            stream_mode="messages",
        ):
            # print(chunk[0].content, end="")
            # print(chunk)
            data = chunk[1]
            print(data["name"])
            if isinstance(chunk[0], AIMessageChunk):
                full_messages += chunk[0].content

        print(f"full_messages: {full_messages}")


# async def main():
#     bot = ChatBot()
#     await bot.generate_test("æŸ¥è¯¢æ­å·çš„å¤©æ°”")
#
#
# if __name__ == "__main__":
#     asyncio.run(main())
